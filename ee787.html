<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>EE787: Fundamentals of Machine Learning </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Jong-Han Kim</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="biography.html">Biography</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="topics.html">Topics</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="ee786.html">EE786&nbsp;Optimization&nbsp;app.</a></div>
<div class="menu-item"><a href="ee370.html">EE370&nbsp;Software&nbsp;lab.</a></div>
<div class="menu-item"><a href="ee363.html">EE363&nbsp;Automatic&nbsp;control</a></div>
<div class="menu-item"><a href="ee212.html">EE212&nbsp;Adventure&nbsp;design</a></div>
<div class="menu-item"><a href="ee787.html" class="current">EE787&nbsp;Machine&nbsp;learning</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>EE787: Fundamentals of Machine Learning </h1>
<div id="subtitle"><a href="http://jonghank.khu.ac.kr">Prof. Jong-Han Kim</a>, <a href="http://www.khu.ac.kr">Kyung Hee University</a>, Autumn 2018 </div>
</div>
<div class="infoblock">
<div class="blockcontent">
<h2>Announcements</h2>
<ul>
<li><p>The class will not meet on Thursday, Nov 8th. </p>
</li>
<li><p>Homework #3 was posted.</p>
</li>
<li><p>The class will not meet on Thursday, Oct 18th. You may submit your homeworks on the next Tuesday.</p>
</li>
<li><p>Homework #2 was posted.</p>
</li>
<li><p>Welcome to EE787: Fundamentals of machine learning.</p>
</li>
</ul>
</div></div>
<h2>Course Info.</h2>
<p><b>Course descriptions</b> </p>
<ul>
<li><p>Fundamental concepts and theories in machine learning, supervised and unsupervised learning, regression and classification, loss function selection and its effect on learning, regularization and robustness to outliers, numerical experiments on data from a wide variety of engineering and other discplines.</p>
</li>
</ul>
<p><b>Lectures</b> </p>
<ul>
<li><p>Tue/Thr 13:30-14:45 (Rm.211-1)</p>
</li>
</ul>
<p><b>Office hours</b></p>
<ul>
<li><p>Tue/Thr 15:00-16:00 (Rm.516), or by appointments if you cannot meet them.</p>
</li>
</ul>
<p><b>Prerequisites</b> </p>
<ul>
<li><p>Previous exposure to linear algebra, probability, and programming.</p>
</li>
<li><p>Working knowledge on optimization will be a plus.</p>
</li>
</ul>
<p><b>Reference textbooks</b> <br /></p>
<ul>
<li><p>There are no required textbooks.</p>
</li>
<li><p><a href="http://vmls-book.org">Introduction to applied linear algebra - vectors, matrices, and least squares</a>
by Boyd and Vandenberghe will be a useful reference.</p>
</li>
</ul>
<p><b>Grading policy</b></p>
<ul>
<li><p>No exams.</p>
</li>
<li><p>Students will be evaluated by their homework assignments.</p>
</li>
</ul>
<h2>Lecture notes</h2>
<p><i>The course material is reproduced from the <a href="http://ee104.stanford.edu">EE104: Introduction to machine learning</a> by <a href="http://lall.stanford.edu">Sanjay Lall</a> and <a href="http://web.stanford.edu/~boyd/">Stephen Boyd</a> at Stanford university, under their kind permission.</i></p>
<ol>
<li><p><a href="./ee787/ee787_01_overview.pdf">Course overview</a></p>
</li>
<li><p><a href="./ee787/ee787_02_supervised.pdf">Supervised learning via empirical risk minimization</a></p>
</li>
<li><p><a href="./ee787/ee787_03_regression.pdf">Least squares linear regression</a></p>
</li>
<li><p><a href="./ee787/ee787_04_validation.pdf">Validation</a></p>
</li>
<li><p><a href="./ee787/ee787_05_features.pdf">Features</a></p>
</li>
<li><p><a href="./ee787/ee787_06_regularization.pdf">Regularization</a></p>
</li>
<li><p><a href="./ee787/ee787_07_example.pdf">House prices example</a></p>
</li>
<li><p><a href="./ee787/ee787_08_losses.pdf">Non-quadratic losses</a></p>
</li>
<li><p><a href="./ee787/ee787_09_regularizers.pdf">Non-quadratic regularizers</a></p>
</li>
<li><p><a href="./ee787/ee787_10_optimization.pdf">Optimization</a></p>
</li>
<li><p><a href="./ee787/ee787_11_prox_gradient.pdf">Prox-gradient method</a></p>
</li>
<li><p><a href="./ee787/ee787_12_boolean_classification.pdf">Boolean classification</a></p>
</li>
<li><p><a href="./ee787/ee787_13_multiclass.pdf">Multi-class classification</a></p>
</li>
<li><p><a href="./ee787/ee787_14_neural.pdf">Neural networks</a></p>
</li>
<li><p><a href="./ee787/ee787_15_unsupervised.pdf">Unsupervised learning</a></p>
</li>
<li><p><a href="./ee787/ee787_16_pca.pdf">Principal component analysis</a></p>
</li>
</ol>
<h2>Assignments</h2>
<p><i>Several sets of occasional homeworks will be assigned. 
You are encouraged to work in groups, however everyone should turn in his/her own work.</i></p>
<ol>
<li><p><a href="./ee787/ee787_hw1.pdf">Homework 1</a> (due 10/4): <a href="./ee787/files/nearest_neighbor_data.json">nearest_neighbor_data.json</a>, <a href="./ee787/files/fitting_outliers.json">fitting_outliers.json</a>, <a href="./ee787/files/all_pairs_data.json">all_pairs_data.json</a></p>
</li>
<li><p><a href="./ee787/ee787_hw2.pdf">Homework 2</a> (due 10/18): <a href="./ee787/files/inductor_data.json">inductor_data.json</a>, <a href="./ee787/files/rational_fit_data.json">rational_fit_data.json</a>, <a href="./ee787/files/prostate_cancer_data.json">prostate_cancer_data.json</a>, <a href="./ee787/files/to_one_hot.jl">to_one_hot.jl</a></p>
</li>
<li><p><a href="./ee787/ee787_hw3.pdf">Homework 3</a> (due 11/15): <a href="./ee787/files/power_demand_data.json">power_demand_data.json</a></p>
</li>
<li><p><a href="./ee787/ee787_hw4.pdf">Homework 4</a> (due 11/27): <a href="./ee787/files/tomodata_fullysampled.json">tomodata_fullysampled.json</a>, <a href="./ee787/files/tomodata_undersampled.json">tomodata_undersampled.json</a>, <a href="./ee787/files/line_pixel_length.jl">line_pixel_length.jl</a>, <a href="./ee787/files/TV_inpainting.ipynb">TV_inpainting.ipynb</a></p>
</li>
<li><p><a href="./ee787/ee787_hw5.pdf">Homework 5</a> (optional): <a href="./ee787/files/homework_scores.csv">homework_scores.csv</a></p>
</li>
</ol>
<h2>Julia</h2>
<p><b>Julia language</b></p>
<ul>
<li><p>We will be using Julia, which excels in high performance technical computing, for homework assignments.</p>
</li>
<li><p>You are not expected to have a strong background in programming (with Julia or otherwise), because the program you will write will use only a tiny subset of Julia's (many and powerful) features.</p>
</li>
</ul>
<p><b>Reference webpages</b></p>
<ul>
<li><p><a href="http://julialang.org">The official Julia webpage</a></p>
</li>
<li><p><a href="http://juliabox.com">JuliaBox: an easy-to-use online platform of Julia</a></p>
</li>
<li><p><a href="http://juliacomputing.com">A variety of Julia product packages including JuliaPro</a></p>
</li>
<li><p><a href="http://web.stanford.edu/class/ee103/julia.html">A short Julia tutorial</a> from <a href="http://ee103.stanford.edu">EE103: Introduction to Matrix Methods</a> at Stanford university.</p>
</li>
<li><p><a href="http://web.stanford.edu/~boyd/vmls/vmls-julia-companion.pdf">Julia language companion</a> by Boyd and Vandenberghe.</p>
</li>
</ul>
<h2>Files</h2>
<p><i>These are some data and the Julia codes in .ipynb notebook files that we are using for lectures or homework assignments.
To run .ipynb files, first download the code by right-clicking “code” and clicking “Save link as…”. 
Then, upload the file to JuliaBox with the “upload” button under the “Jupyter” tab.</i></p>
<ol>
<li><p>Julia example: <a href="./ee787/files/khu_logo_compression.html">KHU logo was a guitar pick.</a> (<a href="./ee787/files/khulogo.jpg">khulogo.jpg</a>, <a href="./ee787/files/khu_logo_compression.ipynb">khu_logo_compression.ipynb</a>)</p>
</li>
<li><p>Julia example: <a href="./ee787/files/huber-based_dynamical_system_estimation.html">Huber-based dynamical system estimation.</a> (<a href="./ee787/files/huber-based_dynamical_system_estimation.ipynb">huber-based_dynamical_system_estimation.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/diabetes.html">JHK is safe from diabetes.</a> (<a href="./ee787/files/diabetes.data">diabetes.data</a>, <a href="./ee787/files/diabetes.ipynb">diabetes.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/polynomial_fit.html">Polynomial fit.</a> (<a href="./ee787/files/polynomial_fit.ipynb">polynomial_fit.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/monomial-exponential_fit.html">Monomial-exponential fit.</a> (<a href="./ee787/files/monomial-exponential_fit.ipynb">monomial-exponential_fit.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/readclassjson_example.html">.json file read example.</a> (<a href="./ee787/files/readclassjson.jl">readclassjson.jl</a>)</p>
</li>
<li><p><a href="./ee787/files/Different_norms.html">Different norms.</a> (<a href="./ee787/files/Different_norms.ipynb">Different_norms.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/Sound_signal_recovery.html">Sound signal recovery.</a> (<a href="./ee787/files/Sound_signal_recovery.ipynb">Sound_signal_recovery.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/TV_inpainting.html">TV_inpainting.</a> (<a href="./ee787/files/neo_bw.png">neo_bw.png</a>, <a href="./ee787/files/neo_bw_corrupted.png">neo_bw_corrupted.png</a>, <a href="./ee787/files/corrupted_image.json">corrupted_image.json</a>, <a href="./ee787/files/TV_inpainting.ipynb">TV_inpainting.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/Network_topology.html">Network topology identification.</a> (<a href="./ee787/files/Network_topology.ipynb">Network_topology.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/ls_lr_svm.html">Least squares classifier, logistic regression, and support vector machine.</a> (<a href="./ee787/files/ls_lr_svm.ipynb">ls_lr_svm.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/iris.html">Iris classification.</a> (<a href="./ee787/files/iris.csv">iris.csv</a>, <a href="./ee787/files/iris.ipynb">iris.ipynb</a>)</p>
</li>
<li><p><a href="./ee787/files/handwriting.html">Handwriting image classification.</a> (<a href="./ee787/files/mnist_train.csv">mnist_train.csv</a>, <a href="./ee787/files/mnist_test.csv">mnist_test.csv</a>, <a href="./ee787/files/handwriting.ipynb">handwriting.ipynb</a>)</p>
</li>
</ol>
<div id="footer">
<div id="footer-text">
Page generated 2019-03-05, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
